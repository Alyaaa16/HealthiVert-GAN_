{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2D SE-ResNet50 Classifier Training for Vertebral Fracture Detection\n",
        "\n",
        "This notebook trains a binary classifier (Normal vs. Fracture) on 2D sagittal slices of straightened vertebrae. \n",
        "The trained model is required for generating Grad-CAM heatmaps used in the HealthiVert-GAN pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install MONAI if not already installed\n",
        "!pip install monai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from monai.networks.nets import SEresnet50\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    EnsureChannelFirst,\n",
        "    Resize,\n",
        "    ScaleIntensity,\n",
        "    ToTensor,\n",
        "    RandRotate,\n",
        "    RandFlip,\n",
        "    RandZoom\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Configuration\n",
        "# ==========================================\n",
        "\n",
        "# Root directory for the project\n",
        "PROJECT_ROOT = Path(\"..\").resolve()\n",
        "\n",
        "# --- UPDATE THESE PATHS FOR KAGGLE ---\n",
        "# If you generated 30 samples to /kaggle/working/straighten_30s, point there:\n",
        "DATA_DIR = Path(\"/kaggle/working/straighten_30s/CT\")\n",
        "\n",
        "# Path to the vertebra_data.json\n",
        "JSON_PATH = Path(\"/kaggle/input/verse-19-genant-fracture-grades/vertebra_data.json\")\n",
        "\n",
        "OUTPUT_DIR = Path(\"./checkpoints\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_EPOCHS = 20\n",
        "IMAGE_SIZE = (256, 256)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "print(f\"Data Directory: {DATA_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Dataset Definition\n",
        "# ==========================================\n",
        "\n",
        "class SagittalSliceDataset(Dataset):\n",
        "    def __init__(self, data_dir, json_path, split='train', transform=None, slice_range=15):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_dir (Path): Path to straightened CT nifti files.\n",
        "            json_path (Path): Path to vertebra_data.json.\n",
        "            split (str): 'train' or 'test'.\n",
        "            transform (callable): MONAI transforms.\n",
        "            slice_range (int): Number of slices +/- from center to extract (Total = 2*range).\n",
        "        \"\"\"\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.slice_range = slice_range\n",
        "        self.samples = []\n",
        "\n",
        "        # Load Labels\n",
        "        with open(json_path, 'r') as f:\n",
        "            labels_data = json.load(f)\n",
        "        \n",
        "        # Use training data for training, test for validation\n",
        "        if split not in labels_data:\n",
        "            raise ValueError(f\"Split {split} not found in json\")\n",
        "            \n",
        "        split_data = labels_data[split]\n",
        "        \n",
        "        # Scan directory\n",
        "        nii_files = list(data_dir.glob(\"*.nii.gz\"))\n",
        "        \n",
        "        print(f\"Scanning {len(nii_files)} files for split '{split}'...\")\n",
        "\n",
        "        for file_path in tqdm(nii_files):\n",
        "            # Filename format: subject_vertID.nii.gz (e.g., sub-verse004_16.nii.gz)\n",
        "            # Logic to match JSON keys which are also subject_vertID\n",
        "            filename = file_path.name.replace('.nii.gz', '')\n",
        "            \n",
        "            # Check if this filename exists in the current split's labels\n",
        "            # This automatically handles the case where we only have a subset of data\n",
        "            if filename in split_data:\n",
        "                grade = split_data[filename]\n",
        "                # Binary Label: 0=Normal, 1=Fracture (Grade > 0)\n",
        "                label = 1 if grade > 0 else 0\n",
        "                \n",
        "                self.samples.append({\n",
        "                    'path': str(file_path),\n",
        "                    'label': label,\n",
        "                    'id': filename\n",
        "                })\n",
        "        \n",
        "        # Balance check\n",
        "        neg = sum(1 for s in self.samples if s['label'] == 0)\n",
        "        pos = sum(1 for s in self.samples if s['label'] == 1)\n",
        "        print(f\"Found {len(self.samples)} volumes. Normal: {neg}, Fracture: {pos}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "        path = sample['path']\n",
        "        label = sample['label']\n",
        "        \n",
        "        try:\n",
        "            img_nii = nib.load(path)\n",
        "            img_arr = img_nii.get_fdata()\n",
        "            \n",
        "            # Extract Sagittal Slice\n",
        "            z_center = img_arr.shape[2] // 2\n",
        "            low = max(0, z_center - self.slice_range)\n",
        "            high = min(img_arr.shape[2], z_center + self.slice_range)\n",
        "            \n",
        "            # Random slice for training robustness\n",
        "            slice_idx = random.randint(low, high - 1) if high > low else z_center\n",
        "            \n",
        "            # Extract 2D slice from the center of the 3D volume\n",
        "            slice_img = img_arr[:, :, slice_idx]\n",
        "            \n",
        "            # Add Channel Dimension (1, H, W)\n",
        "            slice_img = slice_img[np.newaxis, ...]\n",
        "            \n",
        "            if self.transform:\n",
        "                slice_img = self.transform(slice_img)\n",
        "            \n",
        "            return slice_img.float(), torch.tensor(label).long()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {path}: {e}\")\n",
        "            return torch.zeros((1, 256, 256)), torch.tensor(0).long()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Transforms\n",
        "# ==========================================\n",
        "\n",
        "train_transforms = Compose([\n",
        "    ScaleIntensity(),\n",
        "    Resize(spatial_size=IMAGE_SIZE),\n",
        "    # Augmentation\n",
        "    RandRotate(range_x=np.pi/12, prob=0.5, keep_size=True),\n",
        "    RandFlip(spatial_axis=1, prob=0.5),\n",
        "    RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "val_transforms = Compose([\n",
        "    ScaleIntensity(),\n",
        "    Resize(spatial_size=IMAGE_SIZE),\n",
        "    ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Data Loaders\n",
        "# ==========================================\n",
        "\n",
        "train_ds = SagittalSliceDataset(\n",
        "    data_dir=DATA_DIR, \n",
        "    json_path=JSON_PATH, \n",
        "    split='train', \n",
        "    transform=train_transforms\n",
        ")\n",
        "\n",
        "val_ds = SagittalSliceDataset(\n",
        "    data_dir=DATA_DIR, \n",
        "    json_path=JSON_PATH, \n",
        "    split='test', \n",
        "    transform=val_transforms\n",
        ")\n",
        "\n",
        "# Weighted Sampler for Class Imbalance\n",
        "labels = [s['label'] for s in train_ds.samples]\n",
        "if len(labels) > 0:\n",
        "    class_counts = np.bincount(labels)\n",
        "    weights = 1. / (class_counts + 1e-6) # add small epsilon\n",
        "    samples_weights = weights[labels]\n",
        "    sampler = torch.utils.data.WeightedRandomSampler(samples_weights, len(samples_weights))\n",
        "    shuffle = False\n",
        "else:\n",
        "    sampler = None\n",
        "    shuffle = True\n",
        "    print(\"Warning: No samples found! Check paths.\")\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, shuffle=shuffle if sampler is None else False, num_workers=4)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Model Setup\n",
        "# ==========================================\n",
        "\n",
        "model = SEresnet50(\n",
        "    spatial_dims=2,\n",
        "    in_channels=1,\n",
        "    num_classes=2  # 0: Normal, 1: Fracture\n",
        ").to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Training Loop\n",
        "# ==========================================\n",
        "\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    \n",
        "    # --- TRAINING ---\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    all_preds, all_labels = [], []\n",
        "    \n",
        "    for images, targets in tqdm(train_loader):\n",
        "        images, targets = images.to(DEVICE), targets.to(DEVICE)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(targets.cpu().numpy())\n",
        "        \n",
        "    if len(train_loader) > 0:\n",
        "        epoch_loss = train_loss / len(train_loader)\n",
        "        train_acc = accuracy_score(all_labels, all_preds)\n",
        "        print(f\"Train Loss: {epoch_loss:.4f}, Acc: {train_acc:.4f}\")\n",
        "    \n",
        "    # --- VALIDATION ---\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_preds, val_labels = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, targets in val_loader:\n",
        "            images, targets = images.to(DEVICE), targets.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "            \n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(targets.cpu().numpy())\n",
        "            \n",
        "    if len(val_loader) > 0:\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
        "        print(f\"Val Loss: {val_loss/len(val_loader):.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n",
        "        \n",
        "        # Save Best Model\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            save_path = OUTPUT_DIR / \"best_ckpt.tar\"\n",
        "            torch.save({\n",
        "                'state_dict': model.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'accuracy': best_acc\n",
        "            }, save_path)\n",
        "            print(f\"New Best Model Saved to {save_path}!\")\n",
        "\n",
        "print(\"Training Complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Validation Report\n",
        "# ==========================================\n",
        "\n",
        "if len(val_labels) > 0:\n",
        "    print(\"Classification Report ON TEST SET:\")\n",
        "    print(classification_report(val_labels, val_preds, target_names=['Normal', 'Fracture']))\n",
        "else:\n",
        "    print(\"No validation data found to report.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
